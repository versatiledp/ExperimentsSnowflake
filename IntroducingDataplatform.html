
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Introducing data platform &#8212; Snowflake 9/28/2020 documentation</title>
    <link rel="stylesheet" href="static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="static/my.css" type="text/css" />
    <link rel="stylesheet" href="static/copybutton.css" type="text/css" />
    <script id="documentation_options" data-url_root="./" src="static/documentation_options.js"></script>
    <script src="static/jquery.js"></script>
    <script src="static/underscore.js"></script>
    <script src="static/doctools.js"></script>
    <script src="static/language_data.js"></script>
    <script src="static/clipboard.min.js"></script>
    <script src="static/copybutton.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="CSV ingestion" href="CSV_Ingestion.html" />
    <link rel="prev" title="Introducing Snowflake" href="IntroducingSnowflake.html" />
   
  <link rel="stylesheet" href="static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="introducing-data-platform">
<h1>Introducing data platform<a class="headerlink" href="#introducing-data-platform" title="Permalink to this headline">¶</a></h1>
<div class="section" id="data-platform-overview">
<h2>Data platform overview<a class="headerlink" href="#data-platform-overview" title="Permalink to this headline">¶</a></h2>
<p>Modern data architecture allow enterprises to ingest data coming from
multiple systems, variety of data formats, at different speeds, and unknown
intervals. Layered data platform design makes it easy to process big
data efficiently. It enables organizations to quickly deploy new data
analytics business case driven solutions to drive revenue and
profitability.</p>
<p>There are four main pillers of modern data platform:</p>
<ul class="simple">
<li><p>Data source layer</p></li>
<li><p>Data processing and storage layer</p></li>
<li><p>Analytics layer</p></li>
<li><p>Consumption layer</p></li>
</ul>
<div class="section" id="data-source-layer">
<h3>Data source layer<a class="headerlink" href="#data-source-layer" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Data sources can be inside the enterprise or external.</p></li>
<li><p>Data sources generate data in real-time and in batch mode.</p></li>
<li><p>A <strong>variety</strong> of data formats can be  structured, semi-structured, or unstructured.</p></li>
<li><p>The <strong>velocity</strong> (speed of arrival) and <strong>volume</strong> (delivery amount) will differ by sources.</p></li>
</ul>
</div>
<div class="section" id="data-processing-and-storage-layer">
<h3>Data processing and storage layer<a class="headerlink" href="#data-processing-and-storage-layer" title="Permalink to this headline">¶</a></h3>
<p>Data processing layer receives data from the data sources, converts the data into a format
comprehensible for the data servicing and analytics tool, and stores the
data. For example, large amounts of data is
stored in the Hadoop distributed file system store (HDFS). Large data
processing is performed through Hadoop/Spark system. Data may
undergo format changes as it is processed through these systems. Cloud
service providers like Amazon, Google, and Microsoft allow a user to build and
operate data-centric applications with an infinite scale. Robust and
inexpensive storage is fundamental to the operation and scalability of
big data architecture.</p>
<p>BigQuery, Azure Synapse,Amazon Redshift, and Snowflake
are used as standalone solutions for big data processing or in
combination of Hadoop/Spark ecosystems.</p>
</div>
<div class="section" id="analytics-layer">
<h3>Analytics layer<a class="headerlink" href="#analytics-layer" title="Permalink to this headline">¶</a></h3>
<p>The Analytics layer reads the data ingested and transformed by the data
processing and storage layer of big data ecosystem. This layer consists
varieties of data analytic tools for different user requirements. This
layer provides the data discovery mechanisms from  huge volumes of
data. Apache spark SQL, Hive, Apache spark streaming, Machine learning
libraries, Apache spark GraphX, SQL libraries, and number of other tool
sets are utilized in this layer to understand underlying data landscape.</p>
</div>
<div class="section" id="consumption-layer">
<h3>Consumption layer<a class="headerlink" href="#consumption-layer" title="Permalink to this headline">¶</a></h3>
<p>Consumption layer is also called the business intelligence layer. This layer
receives results from the Analytical layer and presents the results
using visualization tools, and
business processes.</p>
<p>The following diagram summarize layers in data management solution.</p>
<div class="figure align-center">
<img alt="images/DataPlatform.jpg" src="images/DataPlatform.jpg" />
</div>
</div>
</div>
<div class="section" id="project-data-source">
<h2>Project data source<a class="headerlink" href="#project-data-source" title="Permalink to this headline">¶</a></h2>
<p>The Institute of Education Sciences (IES) is the statistics, research, and evaluation arm of the U.S. Department
of Education. IES is independent and non-partisan.
IES mission is to provide scientific evidence on which to ground education practice and policy
and to share this information in formats that are useful and accessible to educators,
parents, policymakers, researchers, and the public.</p>
<p>This book is designed to use data from IES and build analytics engine to answer business questions for the corporation.</p>
<p>Integrated Postsecondary Education Data System (IPEDS) - <a class="reference external" href="https://nces.ed.gov/ipeds/">https://nces.ed.gov/ipeds/</a>
is the primary source from IES for the information on U.S. colleges, universities, and technical and vocational institutions.</p>
<ul class="simple">
<li><p>We are tasked to ingest variety of data formats.</p></li>
<li><p>Tranform data for business users.</p></li>
<li><p>Build data pipeline to process data on perodic basis.</p></li>
<li><p>Create descriptive analytics around the use cases laid out by the business.</p></li>
</ul>
<p>All of the data used in this book is downloaded from - <a class="reference external" href="https://nces.ed.gov/ipeds/use-the-data">https://nces.ed.gov/ipeds/use-the-data</a>.</p>
<div class="figure align-center">
<img alt="images/IPEDSScreenShot.png" src="images/IPEDSScreenShot.png" />
</div>
<p>Data is downloaded for the three academic years (2017, 2018, and 2019).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Disclaimer – We have modified this data to explain Snowflake functionality. Analytics results in this book are
used to showcase and learn Snowflake features.
Analytics results from this book should not be used to perform research on the institutions.
Please refer to IES website for  statistics and research for Academic Institutions.</p>
</div>
<p>For this project in the book, we will be following four building block of data transformation layers.</p>
<div class="section" id="staged-file">
<h3>Staged file<a class="headerlink" href="#staged-file" title="Permalink to this headline">¶</a></h3>
<p>All the data from the source system will be brought into the internal Staged file location of the Snowflake.
There is no transformation applied on this dataset.
It is the purest form of data from the transactional system or existing big data platforms.</p>
</div>
<div class="section" id="operation-datastore-od">
<h3>Operation datastore (OD)<a class="headerlink" href="#operation-datastore-od" title="Permalink to this headline">¶</a></h3>
<p>These are first level of physical table created in the Snowflake. Data from staged file is transformed to very basic minimum needs.
OD table structure is very close resembles of staged file with proper data type and column names.
Additional columns to help track on data lineage.</p>
</div>
<div class="section" id="servicing-layer-entities">
<h3>Servicing layer entities<a class="headerlink" href="#servicing-layer-entities" title="Permalink to this headline">¶</a></h3>
<p>This is the final destination for transformed data available for business intelligence layer. OD tables are used as input source to populate the
servicing layer tables.</p>
</div>
<div class="section" id="dataflow-summary">
<h3>Dataflow summary<a class="headerlink" href="#dataflow-summary" title="Permalink to this headline">¶</a></h3>
<p>Not all data from OD tables may land up in the servicing layer. Normally business users would want to use the tools like PowerBI, Tableau, and
perform raw queries on the dataset. Best place for the business users to perform these analytics is the service layer.
Data Science may need data attributes from the staged layer to build predictive analytics.
They can be granted access to OD tables and
service layer entities. Data engineering needs to create transformation, perform metadata management, and
keep track of data pipelines. So the access should be
granted to the all the layers of data platform.</p>
<p>The below diagram shows the data flow process between files and the staging table. In this case, the stored procedures are used to load data from staged files to staging tables.</p>
<div class="figure align-center">
<img alt="images/ingestionlayout.png" src="images/ingestionlayout.png" />
</div>
</div>
</div>
<div class="section" id="data-files">
<h2>Data files<a class="headerlink" href="#data-files" title="Permalink to this headline">¶</a></h2>
<p>The files used in this book are:</p>
<div class="section" id="institutional-characteristics-files-hdr">
<h3>Institutional characteristics files [HDR]<a class="headerlink" href="#institutional-characteristics-files-hdr" title="Permalink to this headline">¶</a></h3>
<p>This file contains directory information for every institution in the IPEDS universe.
It includes name, address, city, state, zip code and various URL links to the institution’s home page,
admissions, financial aid offices and the net price calculator.</p>
</div>
<div class="section" id="month-enrollment-effy">
<h3>12-Month enrollment [EFFY]<a class="headerlink" href="#month-enrollment-effy" title="Permalink to this headline">¶</a></h3>
<p>This file contains the unduplicated headcount of students enrolled over a
12-month period for both undergraduate and graduate levels. Each record is
uniquely defined by the variables IPEDS ID, and the level of enrollment.</p>
</div>
<div class="section" id="admissions-and-test-scores-adm">
<h3>Admissions and test scores [ADM]<a class="headerlink" href="#admissions-and-test-scores-adm" title="Permalink to this headline">¶</a></h3>
<p>This file contains information about the undergraduate selection process
for entering first-time, degree/certificate-seeking students.</p>
</div>
<div class="section" id="student-charges-for-academic-year-programs-ic-ay">
<h3>Student charges for academic year programs [IC*AY]<a class="headerlink" href="#student-charges-for-academic-year-programs-ic-ay" title="Permalink to this headline">¶</a></h3>
<p>This file contains data on student charges for a full academic year. The price of attendance includes
amounts for published tuition and required fees, books and supplies, room and board and other expenses.</p>
</div>
<div class="section" id="code-mapping-data">
<h3>Code mapping data<a class="headerlink" href="#code-mapping-data" title="Permalink to this headline">¶</a></h3>
<p>This is semi structured dataset with special character delimeter. One file holds data for multiple destination table. Based on the value
of the first column in the file, destination table is identified.</p>
</div>
</div>
<div class="section" id="data-collection-notes">
<h2>Data collection notes<a class="headerlink" href="#data-collection-notes" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><ul class="simple">
<li><p>EFFY file is converted to JSON format.</p></li>
<li><p>ADM file is converted to Parquet format.</p></li>
<li><p>IC*AY file is converted to ORC format.</p></li>
<li><p>There is no change in the HDR file format (CSV format).</p></li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Utilities used to convert the original CSV files into different data formats are available to download at: <a class="reference external" href="https://github.com/versatiledp/ExperimentsSnowflake/tree/main/utilities">https://github.com/versatiledp/ExperimentsSnowflake/tree/main/utilities</a></p>
<p>All the datafiles used throughout the books are available to download at:</p>
<p><a class="reference external" href="https://github.com/versatiledp/ExperimentsSnowflake/tree/main/data/input">https://github.com/versatiledp/ExperimentsSnowflake/tree/main/data/input</a></p>
</div>
<p>After downloading the files, copy to the folder C:\Snowflake\data\input\.
The files in this book are loaded from local folder (like C:\Snowflake\data\input\*.*) to the Snowflake stage area using SnowSQL CLI.</p>
<p>We receive data files in various formats like CSV, ORC, Parquet, and JSON. These files are available in the folders by year. They are brought into the Snowflake staged files using the PUT command. Each staged file contains the entire data for that specific year. From these staged files, OD tables are populated. OD tables are physical tables in a Snowflake database.
Using these OD tables, servicing layer tables of data-warehouse are populated. Snowflake stored procedures, views and functions are used for ETL/ELT processes.</p>
</div>
<div class="section" id="ingesting-snowflake-stage">
<h2>Ingesting Snowflake stage<a class="headerlink" href="#ingesting-snowflake-stage" title="Permalink to this headline">¶</a></h2>
<div class="section" id="internal-stage-area-for-ipeds">
<h3>Internal stage area for IPEDS<a class="headerlink" href="#internal-stage-area-for-ipeds" title="Permalink to this headline">¶</a></h3>
<p>We are going to load different file formats like CSV, JSON, Parquet, and ORC.
Internal named stage needs to be created for each of the file formats before loading data.</p>
</div>
<div class="section" id="create-internal-stage-area-ipeds">
<h3>Create internal stage area IPEDS<a class="headerlink" href="#create-internal-stage-area-ipeds" title="Permalink to this headline">¶</a></h3>
<p>Create the file formats and stage area for the text file having:</p>
<blockquote>
<div><ul class="simple">
<li><p>tab delimited</p></li>
<li><p>comma separated with no header</p></li>
<li><p>comma separated with header</p></li>
</ul>
</div></blockquote>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span> <span class="n">Number</span> <span class="n">of</span> <span class="n">header</span> <span class="n">lines</span> <span class="n">at</span> <span class="n">the</span> <span class="n">start</span> <span class="n">of</span> <span class="n">the</span> <span class="n">file</span><span class="o">.</span>
<span class="o">--</span> <span class="n">The</span> <span class="n">COPY</span> <span class="n">command</span> <span class="n">skips</span> <span class="n">header</span> <span class="n">lines</span> <span class="n">when</span> <span class="n">loading</span> <span class="n">data</span>
<span class="o">--</span> <span class="n">All</span> <span class="n">these</span> <span class="n">file</span> <span class="n">formats</span> <span class="n">can</span> <span class="n">be</span> <span class="n">used</span> <span class="n">to</span> <span class="n">create</span> <span class="n">different</span> <span class="n">stage</span> <span class="n">areas</span>
<span class="n">CREATE</span> <span class="n">OR</span> <span class="n">REPLACE</span>  <span class="n">FILE</span> <span class="n">FORMAT</span>
                <span class="n">ff_IPEDS_CSVSkipHeaderTabDelimited</span>
                        <span class="n">TYPE</span> <span class="o">=</span>   <span class="n">CSV</span>
                        <span class="n">FIELD_DELIMITER</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span>  <span class="n">COMPRESSION</span> <span class="o">=</span> <span class="n">AUTO</span>
                        <span class="n">SKIP_HEADER</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="n">CREATE</span> <span class="n">OR</span> <span class="n">REPLACE</span>  <span class="n">FILE</span> <span class="n">FORMAT</span>
                <span class="n">ff_IPEDS_CSVSkipHeaderCommaDelimited</span>
                        <span class="n">TYPE</span> <span class="o">=</span>   <span class="n">CSV</span>
                        <span class="n">FIELD_DELIMITER</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span>  <span class="n">COMPRESSION</span> <span class="o">=</span> <span class="n">AUTO</span>
                        <span class="n">SKIP_HEADER</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="o">--</span> <span class="n">The</span> <span class="n">COPY</span> <span class="n">command</span> <span class="n">does</span> <span class="ow">not</span> <span class="n">skip</span> <span class="nb">any</span> <span class="n">lines</span><span class="o">.</span>
<span class="n">CREATE</span> <span class="n">OR</span> <span class="n">REPLACE</span>  <span class="n">FILE</span> <span class="n">FORMAT</span>
                <span class="n">ff_IPEDS_CSVHeaderTabDelimited</span>
                        <span class="n">TYPE</span> <span class="o">=</span>   <span class="n">CSV</span>
                        <span class="n">FIELD_DELIMITER</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span>  <span class="n">COMPRESSION</span> <span class="o">=</span> <span class="n">AUTO</span>
                        <span class="n">SKIP_HEADER</span> <span class="o">=</span> <span class="mi">0</span> <span class="p">;</span>
<span class="n">CREATE</span> <span class="n">OR</span> <span class="n">REPLACE</span>  <span class="n">FILE</span> <span class="n">FORMAT</span>
                <span class="n">ff_IPEDS_CSVHeaderCommaDelimited</span>
                        <span class="n">TYPE</span> <span class="o">=</span>   <span class="n">CSV</span>
                        <span class="n">FIELD_DELIMITER</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span>  <span class="n">COMPRESSION</span> <span class="o">=</span> <span class="n">AUTO</span>
                        <span class="n">SKIP_HEADER</span> <span class="o">=</span> <span class="mi">0</span> <span class="n">encoding</span> <span class="o">=</span> <span class="s1">&#39;iso-8859-1&#39;</span>
                        <span class="n">FIELD_OPTIONALLY_ENCLOSED_BY</span><span class="o">=</span><span class="s1">&#39;&quot;&#39;</span><span class="p">;</span>
<span class="o">--</span> <span class="n">create</span> <span class="n">satge</span> <span class="n">area</span> <span class="n">to</span> <span class="n">load</span> <span class="n">csv</span> <span class="n">files</span> <span class="k">for</span> <span class="n">the</span> <span class="n">project</span>
<span class="n">CREATE</span> <span class="n">OR</span> <span class="n">REPLACE</span> <span class="n">STAGE</span> <span class="n">IPEDS_HD</span> <span class="n">FILE_FORMAT</span>
                        <span class="o">=</span> <span class="n">ff_IPEDS_CSVHeaderCommaDelimited</span><span class="p">;</span>
<span class="n">CREATE</span> <span class="n">OR</span> <span class="n">REPLACE</span> <span class="n">STAGE</span> <span class="n">IPEDS_CM</span> <span class="n">FILE_FORMAT</span>
                        <span class="o">=</span> <span class="n">ff_IPEDS_CSVSkipHeaderTabDelimited</span><span class="p">;</span>
</pre></div>
</div>
<p>— Create JSON file format &amp; stage area</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span> <span class="n">Create</span> <span class="n">file</span> <span class="nb">format</span> <span class="n">to</span> <span class="n">load</span> <span class="n">JSON</span> <span class="n">file</span>
<span class="n">CREATE</span> <span class="n">OR</span> <span class="n">REPLACE</span> <span class="n">FILE</span> <span class="n">FORMAT</span> <span class="n">ff_IPEDS_Json</span>
                <span class="n">TYPE</span> <span class="o">=</span><span class="n">JSON</span> <span class="n">TRIM_SPACE</span> <span class="o">=</span> <span class="n">TRUE</span><span class="p">;</span>
<span class="o">--</span> <span class="n">Create</span> <span class="n">stage</span> <span class="n">area</span> <span class="n">to</span> <span class="n">load</span> <span class="n">JSON</span> <span class="n">file</span>
<span class="n">CREATE</span> <span class="n">OR</span> <span class="n">REPLACE</span> <span class="n">stage</span> <span class="n">IPEDS_EFFY</span> <span class="n">FILE_FORMAT</span> <span class="o">=</span> <span class="n">ff_IPEDS_Json</span><span class="p">;</span>
</pre></div>
</div>
<p>— Create ORC file format &amp; stage area</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span> <span class="n">Create</span> <span class="n">file</span> <span class="nb">format</span> <span class="n">to</span> <span class="n">load</span> <span class="n">ORC</span> <span class="n">file</span>
<span class="n">CREATE</span> <span class="n">OR</span> <span class="n">REPLACE</span> <span class="n">FILE</span> <span class="n">FORMAT</span> <span class="n">ff_IPEDS_ORC</span>
                        <span class="n">TYPE</span> <span class="o">=</span><span class="n">ORC</span> <span class="n">TRIM_SPACE</span> <span class="o">=</span> <span class="n">TRUE</span><span class="p">;</span>
<span class="o">--</span> <span class="n">Create</span> <span class="n">stage</span> <span class="n">area</span> <span class="n">to</span> <span class="n">load</span> <span class="n">ORC</span> <span class="n">file</span>
<span class="n">CREATE</span> <span class="n">OR</span> <span class="n">REPLACE</span> <span class="n">stage</span> <span class="n">IPEDS_IC</span> <span class="n">FILE_FORMAT</span> <span class="o">=</span> <span class="n">ff_IPEDS_ORC</span><span class="p">;</span>
</pre></div>
</div>
<p>— Create Parquet file format &amp; stage area</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span> <span class="n">Create</span> <span class="n">Parquet</span> <span class="n">file</span> <span class="nb">format</span>
<span class="n">CREATE</span> <span class="n">OR</span> <span class="n">REPLACE</span>  <span class="n">FILE</span> <span class="n">FORMAT</span> <span class="n">ff_IPEDS_Parquet</span>
                        <span class="n">TYPE</span> <span class="o">=</span><span class="n">PARQUET</span> <span class="n">TRIM_SPACE</span> <span class="o">=</span> <span class="n">TRUE</span><span class="p">;</span>
<span class="o">--</span> <span class="n">Create</span> <span class="n">stage</span> <span class="n">area</span> <span class="n">to</span> <span class="n">load</span> <span class="n">Parquet</span> <span class="n">file</span>
<span class="n">CREATE</span> <span class="n">OR</span> <span class="n">REPLACE</span> <span class="n">stage</span> <span class="n">IPEDS_ADM</span> <span class="n">FILE_FORMAT</span> <span class="o">=</span> <span class="n">ff_IPEDS_Parquet</span><span class="p">;</span>
</pre></div>
</div>
<p>Once these formats are created, we can check the staged area and formats to load Snowflake internal stage area with:</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">SHOW</span> <span class="n">STAGES</span> <span class="p">;</span>
<span class="n">SHOW</span> <span class="n">STAGES</span> <span class="n">LIKE</span> <span class="s1">&#39;%IPED%&#39;</span><span class="p">;</span>
</pre></div>
</div>
<div class="figure align-center">
<img alt="images/stagefilelist.JPG" src="images/stagefilelist.JPG" />
</div>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">SHOW</span> <span class="n">FILE</span> <span class="n">FORMATS</span><span class="p">;</span>
<span class="n">SHOW</span> <span class="n">FILE</span> <span class="n">FORMATS</span> <span class="n">LIKE</span> <span class="s1">&#39;%IPED%&#39;</span><span class="p">;</span>
</pre></div>
</div>
<div class="figure align-center">
<img alt="images/formats.JPG" src="images/formats.JPG" />
</div>
<p>We have created an internal named stage in Snowflake to ingest CSV files, Parquet file, ORC file, and JSON files.</p>
<p>We will use the following stage area to load the raw files.</p>
<ul class="simple">
<li><p>IPEDS_ADM</p></li>
<li><p>IPEDS_EFFY</p></li>
<li><p>IPEDS_CM</p></li>
<li><p>IPEDS_HD</p></li>
<li><p>IPEDS_IC</p></li>
</ul>
</div>
<div class="section" id="load-the-files-to-internal-stage-for-ipeds">
<h3>Load the files to internal stage for IPEDS<a class="headerlink" href="#load-the-files-to-internal-stage-for-ipeds" title="Permalink to this headline">¶</a></h3>
<p>Connect to the Snowflake database using SnowSQL CLI and load the following files to the staging area.</p>
<p>Load academic institution (HDR) files - These are the CSV files.</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">put</span> <span class="n">file</span><span class="p">:</span><span class="o">//</span><span class="n">C</span><span class="p">:</span>\<span class="n">snowflake</span>\<span class="n">data</span>\<span class="nb">input</span>\<span class="n">HD2017</span><span class="o">.</span><span class="n">csv</span> <span class="nd">@IPEDS_HD</span><span class="p">;</span>
<span class="n">put</span> <span class="n">file</span><span class="p">:</span><span class="o">//</span><span class="n">C</span><span class="p">:</span>\<span class="n">snowflake</span>\<span class="n">data</span>\<span class="nb">input</span>\<span class="n">HD2018</span><span class="o">.</span><span class="n">csv</span> <span class="nd">@IPEDS_HD</span><span class="p">;</span>
<span class="n">put</span> <span class="n">file</span><span class="p">:</span><span class="o">//</span><span class="n">C</span><span class="p">:</span>\<span class="n">snowflake</span>\<span class="n">data</span>\<span class="nb">input</span>\<span class="n">HD2019</span><span class="o">.</span><span class="n">csv</span> <span class="nd">@IPEDS_HD</span><span class="p">;</span>
</pre></div>
</div>
<p>Load enrollment (EFFY) files  - These are the JSON files.</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">put</span> <span class="n">file</span><span class="p">:</span><span class="o">//</span><span class="n">C</span><span class="p">:</span>\<span class="n">snowflake</span>\<span class="n">data</span>\<span class="nb">input</span>\<span class="n">effy2017_rv</span><span class="o">.</span><span class="n">json</span> <span class="nd">@IPEDS_EFFY</span><span class="p">;</span>
<span class="n">put</span> <span class="n">file</span><span class="p">:</span><span class="o">//</span><span class="n">C</span><span class="p">:</span>\<span class="n">snowflake</span>\<span class="n">data</span>\<span class="nb">input</span>\<span class="n">effy2018_rv</span><span class="o">.</span><span class="n">json</span> <span class="nd">@IPEDS_EFFY</span><span class="p">;</span>
<span class="n">put</span> <span class="n">file</span><span class="p">:</span><span class="o">//</span><span class="n">C</span><span class="p">:</span>\<span class="n">snowflake</span>\<span class="n">data</span>\<span class="nb">input</span>\<span class="n">effy2019_rv</span><span class="o">.</span><span class="n">json</span> <span class="nd">@IPEDS_EFFY</span><span class="p">;</span>
</pre></div>
</div>
<p>Load institutional (IC) charges files  - These are the ORC files.
All the partitioned are loaded into specific folder of ORC staging area.</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">put</span> <span class="n">file</span><span class="p">:</span><span class="o">//</span><span class="n">C</span><span class="p">:</span>\<span class="n">snowflake</span>\<span class="n">data</span>\<span class="nb">input</span>\<span class="n">ic2017_ay_orc</span>\<span class="o">*.*</span> <span class="nd">@IPEDS_IC</span><span class="o">/</span><span class="mi">2017</span><span class="o">/</span><span class="p">;</span>
<span class="n">put</span> <span class="n">file</span><span class="p">:</span><span class="o">//</span><span class="n">C</span><span class="p">:</span>\<span class="n">snowflake</span>\<span class="n">data</span>\<span class="nb">input</span>\<span class="n">ic2018_ay_orc</span>\<span class="o">*.*</span> <span class="nd">@IPEDS_IC</span><span class="o">/</span><span class="mi">2018</span><span class="o">/</span><span class="p">;</span>
<span class="n">put</span> <span class="n">file</span><span class="p">:</span><span class="o">//</span><span class="n">C</span><span class="p">:</span>\<span class="n">snowflake</span>\<span class="n">data</span>\<span class="nb">input</span>\<span class="n">ic2019_ay_orc</span>\<span class="o">*.*</span> <span class="nd">@IPEDS_IC</span><span class="o">/</span><span class="mi">2019</span><span class="o">/</span><span class="p">;</span>
</pre></div>
</div>
<p>Load admission files  - These are the Parquet files.
All the partitioned are loaded into specific folder of Parquet staging area.</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">put</span> <span class="n">file</span><span class="p">:</span><span class="o">//</span><span class="n">C</span><span class="p">:</span>\<span class="n">snowflake</span>\<span class="n">data</span>\<span class="nb">input</span>\<span class="n">adm2017</span><span class="o">.</span><span class="n">parquet</span>\<span class="o">*.*</span> <span class="nd">@IPEDS_ADM</span><span class="o">/</span><span class="mi">2017</span><span class="o">/</span><span class="p">;</span>
<span class="n">put</span> <span class="n">file</span><span class="p">:</span><span class="o">//</span><span class="n">C</span><span class="p">:</span>\<span class="n">snowflake</span>\<span class="n">data</span>\<span class="nb">input</span>\<span class="n">adm2018</span><span class="o">.</span><span class="n">parquet</span>\<span class="o">*.*</span> <span class="nd">@IPEDS_ADM</span><span class="o">/</span><span class="mi">2018</span><span class="o">/</span><span class="p">;</span>
<span class="n">put</span> <span class="n">file</span><span class="p">:</span><span class="o">//</span><span class="n">C</span><span class="p">:</span>\<span class="n">snowflake</span>\<span class="n">data</span>\<span class="nb">input</span>\<span class="n">adm2019</span><span class="o">.</span><span class="n">parquet</span>\<span class="o">*.*</span> <span class="nd">@IPEDS_ADM</span><span class="o">/</span><span class="mi">2019</span><span class="o">/</span><span class="p">;</span>
</pre></div>
</div>
<p>Load code mapping files  - These are the CSV files.</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">put</span> <span class="n">file</span><span class="p">:</span><span class="o">//</span><span class="n">C</span><span class="p">:</span>\<span class="n">snowflake</span>\<span class="n">data</span>\<span class="nb">input</span>\<span class="n">CodeMappingData</span><span class="o">.</span><span class="n">txt</span> <span class="nd">@IPEDS_CM</span><span class="p">;</span>
</pre></div>
</div>
<p>Once these files are loaded to the stage area, we can check the availability of
these data files in the internal stage area as below:</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">list</span> <span class="nd">@IPEDS_HD</span><span class="p">;</span>
</pre></div>
</div>
<div class="figure align-center">
<img alt="images/csvlist.JPG" src="images/csvlist.JPG" />
</div>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">list</span> <span class="nd">@IPEDS_EFFY</span><span class="p">;</span>
</pre></div>
</div>
<div class="figure align-center">
<img alt="images/jsonlist.JPG" src="images/jsonlist.JPG" />
</div>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">list</span> <span class="nd">@IPEDS_IC</span><span class="p">;</span>
</pre></div>
</div>
<div class="figure align-center">
<img alt="images/stagedORC.JPG" src="images/stagedORC.JPG" />
</div>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">list</span> <span class="nd">@IPEDS_ADM</span><span class="p">;</span>
</pre></div>
</div>
<div class="figure align-center">
<img alt="images/Parquetlist.JPG" src="images/Parquetlist.JPG" />
</div>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">list</span> <span class="nd">@IPEDS_CM</span><span class="p">;</span>
</pre></div>
</div>
<div class="figure align-center">
<img alt="images/csvOther.JPG" src="images/csvOther.JPG" />
</div>
<p>All the files from data source layers are ingested into the Snowflake staged area.</p>
<p>If there are any issues in stage area, drop it using <strong>remove &#64;IPEDS_ADM</strong>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Code is available to download at:
<a class="reference external" href="https://github.com/versatiledp/ExperimentsSnowflake/tree/main/source/code/SQL/StagedFile">ExperimentsSnowflake/tree/main/source/code/SQL/StagedFile</a></p>
</div>
</div>
</div>
<div class="section" id="attribute-mapping">
<h2>Attribute mapping<a class="headerlink" href="#attribute-mapping" title="Permalink to this headline">¶</a></h2>
<div class="section" id="academic-institution">
<h3>Academic institution<a class="headerlink" href="#academic-institution" title="Permalink to this headline">¶</a></h3>
<p>Institutional characteristics header files [HDR] are in CSV format.
These files are directly ingested into Snowflake staging from the source system.
ELT layer defines the schema for the CSV file with data types.
The following diagram displays mapping between the CSV attribute and the stage layer.
The OD layer is used to process data for destination layer with additional transformations.</p>
<div class="figure align-center">
<img alt="images/csvIngestion.jpg" src="images/csvIngestion.jpg" />
</div>
</div>
<div class="section" id="enrollment">
<h3>Enrollment<a class="headerlink" href="#enrollment" title="Permalink to this headline">¶</a></h3>
<p>Enrollment files [EFFY] are in JSON format. JSON is an open standard file format, and data interchange format, that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and array data types. It is a very common data format, with a diverse range of applications, such as serving as a replacement for XML in AJAX systems.
In our use case, we are assuming Enrollment files are ingested (EFFY files) in the JSON format directly to Snowflake.
ELT layer defines the mapped attributes for JSON with data types. The following diagram displays mapping between JSON attribute and stage layer. The Stage layer is used to process data for the destination layer with additional transformation.</p>
<div class="figure align-center">
<img alt="images/jsonIngestion.jpg" src="images/jsonIngestion.jpg" />
</div>
</div>
<div class="section" id="institutional-charges">
<h3>Institutional charges<a class="headerlink" href="#institutional-charges" title="Permalink to this headline">¶</a></h3>
<p>Institutional charges [IC] dataset is in the ORC formt. The Optimized Row Columnar (ORC) file format provides a highly efficient way to store Hive data. Using ORC files improves performance when Hive is reading, writing, and processing data. It ideally stores data in compact form and enables skipping over irrelevant parts without the need for large, complex, or manually maintained indices.
In our use case, – we are assuming Institutional Charge text files are ingested (ICAY files) in HDFS. They are processed through Hive. Output of the big data processing (ORC files) are used to load in Snowflake.
ELT layer defines the schema for ORC file with data types. The following diagram displays mapping between the ORC attribute and the stage layer. The stage layer is used to process data for the destination layer with additional transformations and normalization.</p>
<div class="figure align-center">
<img alt="images/orcIngestion.jpg" src="images/orcIngestion.jpg" />
</div>
</div>
<div class="section" id="admission-data">
<h3>Admission data<a class="headerlink" href="#admission-data" title="Permalink to this headline">¶</a></h3>
<p>Admission data [ADM] files are available in the Parquet data format.
Parquet, an open-source file format for Hadoop stores nested data structures in a flat columnar format.
Compared to a traditional approach where data is stored in a row-oriented approach, Parquet is more efficient
in terms of storage and performance. It is especially useful for queries that read specific columns from a wide table.
Parquet provides optimizations to speed up queries. Parquet is a far more efficient file format than CSV or JSON, supported by many
data processing systems. Spark SQL provides support for both reading and writing Parquet files that automatically
capture the schema of the original data. The following diagram lays out the architecture from data source to Parquet file.
In our use case, we are assuming that the IPEDs admission data text files are ingested (ADM files) in HDFS and processed through the Spark.
Output of the spark processing (Parquet files) are used to process in Snowflake.
ELT layer defines the schema for Parquet file with data types. The following diagram displays mapping between
the Parquet attribute and the stage layer. The stage layer is used to process data for the final destination layer with additional transformations.</p>
<div class="figure align-center">
<img alt="images/parquetIngestion.jpg" src="images/parquetIngestion.jpg" />
</div>
</div>
<div class="section" id="reference-lookup-data">
<h3>Reference/Lookup data<a class="headerlink" href="#reference-lookup-data" title="Permalink to this headline">¶</a></h3>
<p>Code value lookup files are CSV formatted. These files are directly ingested into Snowflake staging from source system.
ELT layer defines the schema for the CSV file with data types.</p>
</div>
<div class="section" id="summary">
<h3>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h3>
<p>Data from the source systems goes through multiple data processing layers in transactional and big data platforms. That results into
varieties of data files in the multiple data formats. We need to map those data files into analytical meta data layer. This chapter
summarize all data formats we will be dealing with in the processing layer of analytical data platform.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Mapping between the source system and Snowflake meta data is at:
<a class="reference external" href="https://versatiledp.github.io/ExperimentsSnowflake/Mapping/AcademicInstitute.htm">ExperimentsSnowflake/Mapping/AcademicInstitute</a>
<a class="reference external" href="https://versatiledp.github.io/ExperimentsSnowflake/Mapping/Enrollment.htm">ExperimentsSnowflake/Mapping/Enrollment</a>
<a class="reference external" href="https://versatiledp.github.io/ExperimentsSnowflake/Mapping/InstitutionCharges.htm">ExperimentsSnowflake/Mapping/InstitutionCharges</a>
<a class="reference external" href="https://versatiledp.github.io/ExperimentsSnowflake/Mapping/AdmissionStat.htm">ExperimentsSnowflake/Mapping/AdmissionStat</a>
<a class="reference external" href="https://versatiledp.github.io/ExperimentsSnowflake/Mapping/CodeValue.htm">ExperimentsSnowflake/Mapping/CodeValue</a></p>
</div>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference external" href="./index.html">Table of Contents</a></p></td>
<td><p><a class="reference external" href="./Snowflake.html">Previous Chapter</a></p></td>
<td><p><a class="reference external" href="./Snowflake.html">Next Chapter</a></p></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">Snowflake</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Table of Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="IntroducingSnowflake.html">Introducing Snowflake</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Introducing data platform</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#data-platform-overview">Data platform overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#data-source-layer">Data source layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#data-processing-and-storage-layer">Data processing and storage layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#analytics-layer">Analytics layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#consumption-layer">Consumption layer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#project-data-source">Project data source</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#staged-file">Staged file</a></li>
<li class="toctree-l3"><a class="reference internal" href="#operation-datastore-od">Operation datastore (OD)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#servicing-layer-entities">Servicing layer entities</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dataflow-summary">Dataflow summary</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#data-files">Data files</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#institutional-characteristics-files-hdr">Institutional characteristics files [HDR]</a></li>
<li class="toctree-l3"><a class="reference internal" href="#month-enrollment-effy">12-Month enrollment [EFFY]</a></li>
<li class="toctree-l3"><a class="reference internal" href="#admissions-and-test-scores-adm">Admissions and test scores [ADM]</a></li>
<li class="toctree-l3"><a class="reference internal" href="#student-charges-for-academic-year-programs-ic-ay">Student charges for academic year programs [IC*AY]</a></li>
<li class="toctree-l3"><a class="reference internal" href="#code-mapping-data">Code mapping data</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#data-collection-notes">Data collection notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ingesting-snowflake-stage">Ingesting Snowflake stage</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#internal-stage-area-for-ipeds">Internal stage area for IPEDS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#create-internal-stage-area-ipeds">Create internal stage area IPEDS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#load-the-files-to-internal-stage-for-ipeds">Load the files to internal stage for IPEDS</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#attribute-mapping">Attribute mapping</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#academic-institution">Academic institution</a></li>
<li class="toctree-l3"><a class="reference internal" href="#enrollment">Enrollment</a></li>
<li class="toctree-l3"><a class="reference internal" href="#institutional-charges">Institutional charges</a></li>
<li class="toctree-l3"><a class="reference internal" href="#admission-data">Admission data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reference-lookup-data">Reference/Lookup data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#summary">Summary</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="CSV_Ingestion.html">CSV ingestion</a></li>
<li class="toctree-l1"><a class="reference internal" href="JSON_Ingestion.html">JSON ingestion</a></li>
<li class="toctree-l1"><a class="reference internal" href="ORC_Ingestion.html">ORC ingestion</a></li>
<li class="toctree-l1"><a class="reference internal" href="Parquet_Ingestion.html">Parquet ingestion</a></li>
<li class="toctree-l1"><a class="reference internal" href="Semi_structured_data_Load.html">Semi-structured data Load</a></li>
<li class="toctree-l1"><a class="reference internal" href="Pipeline_Orchestration.html">Pipeline orchestration</a></li>
<li class="toctree-l1"><a class="reference internal" href="Business_Insights.html">Business insights</a></li>
<li class="toctree-l1"><a class="reference internal" href="Summary.html">Summary</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="IntroducingSnowflake.html" title="previous chapter">Introducing Snowflake</a></li>
      <li>Next: <a href="CSV_Ingestion.html" title="next chapter">CSV ingestion</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>

  </body>
</html>